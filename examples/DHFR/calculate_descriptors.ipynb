{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Descriptors\n",
    "\n",
    "\n",
    "This notebook documents the use of transformers to calculate ROBUST descriptors from molecular dynamics simulations. \n",
    "\n",
    "\n",
    "### Disclaimer\n",
    "\n",
    "This notebook is **not** optimized for speed and depending on the size of the dataset can take a very long time to run. A major slowdown is, that all trajectories in this study were stored as tarballs and have to be extracted before descriptors can be calculated.\n",
    "\n",
    "Several obvious strategies can be employed to speed up computation:\n",
    "\n",
    "**1. Store uncompressed trajectories**\n",
    "\n",
    "If storage space is not an issue, uncompressed trajectories can be stored instead. This will eliminate having to copy the tarball to a temporary directory and having to extract the trajectory.\n",
    "\n",
    "**2. Calculate descriptors simultaneously**\n",
    "\n",
    "For demonstration purposes descriptors are calculated sequentially. This means that for each descriptor the trajectory tarball has to be copied and extracted. If one would calculate descriptors simultaneously (i.e. in pass through the dataset) the trajectory would only have to be extracted once.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../../transformers/transformers')\n",
    "from trj_nonbonded_transformer import run as run_nonbonded\n",
    "from trj_rms_transformer import run as run_rms\n",
    "from trj_hbond_transformer import run as run_hbond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "data_dir = os.path.abspath('./data')\n",
    "dataset_path = os.path.join(data_dir,'dataset.csv')\n",
    "\n",
    "dataset = pd.read_csv(dataset_path, sep=',', index_col=0)\n",
    "dataset.rep = dataset.rep.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check file availability\n",
    "\n",
    "Check if descriptors have already been calculated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj = '/storage/DHFR/PJirovecii/{n}/rep{r}/{n}_rep{r}_14-out.tgz'\n",
    "desmond_cms = './data/{n}/rep{r}/{n}_rep{r}_14-out.cms'\n",
    "trj_rms = './data/{n}/rep{r}/{n}_rep{r}_trj_rms.json'\n",
    "trj_nonbonded = './data/{n}/rep{r}/{n}_rep{r}_trj_nonbonded.json'\n",
    "trj_hbonds = './data/{n}/rep{r}/{n}_rep{r}_trj_hbond.csv'\n",
    "com_dist = './data/{n}/rep{r}/{n}_rep{r}_com_dist.csv'\n",
    "\n",
    "for i in dataset.index:\n",
    "    n = dataset.loc[i, 'name']\n",
    "    if not os.path.isdir(os.path.join(data_dir, n)):\n",
    "        os.mkdir(os.path.join(data_dir, n))\n",
    "    r = dataset.loc[i, 'rep']\n",
    "    if not os.path.isdir(os.path.join(data_dir, n, 'rep{}'.format(r))):\n",
    "        os.mkdir(os.path.join(data_dir, n, 'rep{}'.format(r)))\n",
    "    trj_arch = trj.format(n=n, r=r)\n",
    "    if os.path.isfile(trj_arch):\n",
    "        dataset.loc[i, 'raw_trj'] = trj_arch\n",
    "    if os.path.isfile(desmond_cms.format(n=n, r=r)):\n",
    "        dataset.loc[i, 'desmond_cms'] = desmond_cms.format(n=n, r=r)\n",
    "    if os.path.isfile(trj_rms.format(n=n, r=r)):\n",
    "        dataset.loc[i, 'trj_rms'] = trj_rms.format(n=n, r=r)\n",
    "    if os.path.isfile(trj_nonbonded.format(n=n, r=r)):\n",
    "        dataset.loc[i, 'desmond_nonbonded'] = trj_nonbonded.format(n=n, r=r)\n",
    "    if os.path.isfile(trj_hbonds.format(n=n, r=r)):\n",
    "        dataset.loc[i, 'trj_hbonds'] = trj_hbonds.format(n=n, r=r)\n",
    "    if os.path.isfile(com_dist.format(n=n, r=r)):\n",
    "        dataset.loc[i, 'com_dist'] = com_dist.format(n=n, r=r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get desmond_cms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OG4\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.index:\n",
    "    if not dataset.isna().loc[i, 'raw_trj'] and dataset.isna().loc[i, 'desmond_cms']:\n",
    "        n = dataset.loc[i, 'name']\n",
    "        r = int(dataset.loc[i, 'rep'])\n",
    "        print(n, r)\n",
    "        desmond_cms = os.path.join(data_dir, '{n}/rep{r}/{n}_rep{r}_14-out.cms'.format(n=n, r=r))\n",
    "        with tempfile.TemporaryDirectory() as tempdir:\n",
    "            os.chdir(tempdir)\n",
    "            shutil.copy(dataset.loc[i, 'raw_trj'], os.path.join(tempdir,'raw_trj.tgz'))\n",
    "            with tarfile.open('raw_trj.tgz') as tar:\n",
    "                tar.extractall()\n",
    "            tmp_cms = os.path.join(tempdir,'{n}_rep{r}_14/{n}_rep{r}_14-out.cms'.format(n=n, r=r))\n",
    "            shutil.copy(tmp_cms, desmond_cms)\n",
    "        dataset.loc[i, 'desmond_cms'] = desmond_cms                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate nonbonded descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OG4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/scipy/optimize/minpack.py:799: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.index:\n",
    "    if not dataset.isna().loc[i, 'raw_trj'] and dataset.isna().loc[i, 'desmond_nonbonded']:\n",
    "        n = dataset.loc[i, 'name']\n",
    "        r = int(dataset.loc[i, 'rep'])\n",
    "        print(n, r)\n",
    "        with tempfile.TemporaryDirectory() as tempdir:\n",
    "            os.chdir(tempdir)\n",
    "            shutil.copy(dataset.loc[i, 'raw_trj'], os.path.join(tempdir,'raw_trj.tgz'))\n",
    "            with tarfile.open('raw_trj.tgz') as tar:\n",
    "                tar.extractall()\n",
    "            cmsfile = os.path.join(tempdir,'{n}_rep{r}_14/{n}_rep{r}_14-out.cms'.format(n=n, r=r))\n",
    "            cfgfile = os.path.join(tempdir,'{n}_rep{r}_14/{n}_rep{r}_14-out.cfg'.format(n=n, r=r))\n",
    "            trjtar = os.path.join(tempdir,'{n}_rep{r}_14/{n}_rep{r}_14_trj'.format(n=n, r=r))\n",
    "            structure_dict_list = [\n",
    "                                    {'files': {\n",
    "                                        'desmond_cms': cmsfile,\n",
    "                                        'desmond_trjtar': trjtar,\n",
    "                                        'desmond_cfg': cfgfile\n",
    "                                    },\n",
    "                                    'structure': {'code': '{}_rep{}'.format(n,r),\n",
    "                                    'structure_id': 0},\n",
    "                                    'custom':[]\n",
    "                                    }\n",
    "                                    ]\n",
    "            for sd in run_nonbonded(structure_dict_list):\n",
    "                if 'desmond_nonbonded' in sd['files']:\n",
    "                    nonbonded_raw = os.path.join(data_dir, n, 'rep{}'.format(r))\n",
    "                    shutil.copy(sd['files']['desmond_nonbonded'], nonbonded_raw)\n",
    "                    dataset.loc[i, 'desmond_nonbonded'] = os.path.join(nonbonded_raw, sd['files']['desmond_nonbonded'])                         \n",
    "        os.chdir(cwd)\n",
    "            \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate rms descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OG4 3\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.index:\n",
    "    if not dataset.isna().loc[i, 'raw_trj'] and dataset.isna().loc[i, 'trj_rms']:\n",
    "        n = dataset.loc[i, 'name']\n",
    "        r = int(dataset.loc[i, 'rep'])\n",
    "        print(n, r)\n",
    "        with tempfile.TemporaryDirectory() as tempdir:\n",
    "            os.chdir(tempdir)\n",
    "            shutil.copy(dataset.loc[i, 'raw_trj'], os.path.join(tempdir,'raw_trj.tgz'))\n",
    "            with tarfile.open('raw_trj.tgz') as tar:\n",
    "                tar.extractall()\n",
    "            cmsfile = os.path.join(tempdir,'{n}_rep{r}_14/{n}_rep{r}_14-out.cms'.format(n=n, r=r))\n",
    "            trjtar = os.path.join(tempdir,'{n}_rep{r}_14/{n}_rep{r}_14_trj'.format(n=n, r=r))\n",
    "            structure_dict_list = [\n",
    "                                    {'files': {\n",
    "                                        'desmond_cms': cmsfile,\n",
    "                                        'desmond_trjtar': trjtar,\n",
    "                                    },\n",
    "                                    'structure': {'code': '{}_rep{}'.format(n,r),\n",
    "                                    'structure_id': 0},\n",
    "                                    'custom':[]\n",
    "                                    }\n",
    "                                    ]\n",
    "            for sd in run_rms(structure_dict_list):\n",
    "                if 'trj_rms' in sd['files']:\n",
    "                    storage_dir = os.path.join(data_dir, n, 'rep{}'.format(r))\n",
    "                    shutil.copy(sd['files']['trj_rms'], storage_dir)\n",
    "                    dataset.loc[i, 'trj_rms'] = os.path.join(storage_dir, sd['files']['trj_rms'])                         \n",
    "        os.chdir(cwd)\n",
    "            \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate hbond descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OG4 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../transformers/transformers/trj_hbond_transformer.py:202: RuntimeWarning: invalid value encountered in arccos\n",
      "../../transformers/transformers/trj_hbond_transformer.py:98: RuntimeWarning: overflow encountered in exp\n",
      "../../transformers/transformers/trj_hbond_transformer.py:98: RuntimeWarning: overflow encountered in exp\n",
      "../../transformers/transformers/trj_hbond_transformer.py:98: RuntimeWarning: overflow encountered in exp\n",
      "../../transformers/transformers/trj_hbond_transformer.py:98: RuntimeWarning: overflow encountered in exp\n",
      "../../transformers/transformers/trj_hbond_transformer.py:98: RuntimeWarning: overflow encountered in exp\n",
      "../../transformers/transformers/trj_hbond_transformer.py:98: RuntimeWarning: overflow encountered in exp\n",
      "../../transformers/transformers/trj_hbond_transformer.py:98: RuntimeWarning: overflow encountered in exp\n",
      "../../transformers/transformers/trj_hbond_transformer.py:98: RuntimeWarning: overflow encountered in exp\n",
      "../../transformers/transformers/trj_hbond_transformer.py:98: RuntimeWarning: overflow encountered in exp\n",
      "../../transformers/transformers/trj_hbond_transformer.py:98: RuntimeWarning: overflow encountered in exp\n",
      "../../transformers/transformers/trj_hbond_transformer.py:98: RuntimeWarning: overflow encountered in exp\n",
      "../../transformers/transformers/trj_hbond_transformer.py:98: RuntimeWarning: overflow encountered in exp\n",
      "../../transformers/transformers/trj_hbond_transformer.py:98: RuntimeWarning: overflow encountered in exp\n",
      "../../transformers/transformers/trj_hbond_transformer.py:559: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.index:\n",
    "    if not dataset.isna().loc[i, 'raw_trj'] and dataset.isna().loc[i, 'trj_hbonds']:\n",
    "        n = dataset.loc[i, 'name']\n",
    "        r = int(dataset.loc[i, 'rep'])\n",
    "        print(n, r)\n",
    "        with tempfile.TemporaryDirectory() as tempdir:\n",
    "            os.chdir(tempdir)\n",
    "            shutil.copy(dataset.loc[i, 'raw_trj'], os.path.join(tempdir,'raw_trj.tgz'))\n",
    "            with tarfile.open('raw_trj.tgz') as tar:\n",
    "                tar.extractall()\n",
    "            cmsfile = os.path.join(tempdir,'{n}_rep{r}_14/{n}_rep{r}_14-out.cms'.format(n=n, r=r))\n",
    "            trjtar = os.path.join(tempdir,'{n}_rep{r}_14/{n}_rep{r}_14_trj'.format(n=n, r=r))\n",
    "            structure_dict_list = [\n",
    "                                    {'files': {\n",
    "                                        'desmond_cms': cmsfile,\n",
    "                                        'desmond_trjtar': trjtar,\n",
    "                                    },\n",
    "                                    'structure': {'code': '{}_rep{}'.format(n,r),\n",
    "                                    'structure_id': 0},\n",
    "                                    'custom':[]\n",
    "                                    }\n",
    "                                    ]\n",
    "            for sd in run_hbond(structure_dict_list):\n",
    "                if 'trj_hbonds' in sd['files']:\n",
    "                    storage_dir = os.path.join(data_dir, n, 'rep{}'.format(r))\n",
    "                    shutil.copy(sd['files']['trj_hbonds'], storage_dir)\n",
    "                    dataset.loc[i, 'trj_hbonds'] = os.path.join(storage_dir, sd['files']['trj_hbonds'])                         \n",
    "        os.chdir(cwd)\n",
    "            \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate torsion descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate distance between protein and ligand COM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from schrodinger.application.desmond.packages import topo, traj, analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_asl = 'protein and not a.element H'\n",
    "ligand_asl = 'r.ptype TOP and not a.element H'\n",
    "for i in dataset.index:\n",
    "    if not dataset.isna().loc[i, 'raw_trj'] and dataset.isna().loc[i, 'com_dist']:\n",
    "        n = dataset.loc[i, 'name']\n",
    "        r = int(dataset.loc[i, 'rep'])\n",
    "        print(n, r)\n",
    "        storage_dir = os.path.join(data_dir, n, 'rep{}'.format(r))\n",
    "        outfile = '{}_rep{}_com_dist.csv'.format(n, r)\n",
    "        with tempfile.TemporaryDirectory() as tempdir:\n",
    "            os.chdir(tempdir)\n",
    "            shutil.copy(dataset.loc[i, 'raw_trj'], os.path.join(tempdir,'raw_trj.tgz'))\n",
    "            with tarfile.open('raw_trj.tgz') as tar:\n",
    "                tar.extractall()\n",
    "            cmsfile = os.path.join(tempdir,'{n}_rep{r}_14/{n}_rep{r}_14-out.cms'.format(n=n, r=r))\n",
    "            trjdir = os.path.join(tempdir,'{n}_rep{r}_14/{n}_rep{r}_14_trj'.format(n=n, r=r))\n",
    "            msys_model, cms_model = topo.read_cms(cmsfile)\n",
    "            tr = traj.read_traj(trjdir)\n",
    "            protein_com = analysis.Com(msys_model, cms_model, asl=protein_asl)\n",
    "            ligand_com = analysis.Com(msys_model, cms_model, asl=ligand_asl)\n",
    "            dist = analysis.Distance(msys_model, cms_model, protein_com, ligand_com)\n",
    "            results = np.array(analysis.analyze(tr, dist))\n",
    "            np.savetxt(outfile, results, delimiter=',')\n",
    "            shutil.copy(outfile, storage_dir)\n",
    "        dataset.loc[i, 'com_dist'] = os.path.join(storage_dir, outfile)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(dataset_path, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feature matrix\n",
    "\n",
    "Once descriptors have been calculated for all variants we have to combine them in a single feature matrix.\n",
    "For this purpose I have written a shell script, that sequentialy callse process.py and merge.py, generating a feature matrix for each descriptor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: The Schrodinger virtualenv is tied to a specific SCHRODINGER value.\n",
      "This virtualenv is tied to SCHRODINGER=/opt/usershared/software/schrodinger19.1.\n",
      "\n",
      "If you change your SCHRODINGER environment variable, it will break the ability\n",
      "to use the unadorned python command.\n",
      "\n",
      "calculating vdw\n",
      "calculating elec\n",
      "calculating rms\n",
      "calculating hbond\n",
      "merging vdw\n",
      "merging elec\n",
      "merging rms\n",
      "merging hbond\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "Traceback (most recent call last):\n",
      "  File \"../../transformers/utils/merge.py\", line 527, in <module>\n",
      "    raise ValueError('Merging data files requires either the dataset or a pldb api endpoint')\n",
      "ValueError: Merging data files requires either the dataset or a pldb api endpoint\n",
      "Traceback (most recent call last):\n",
      "  File \"../../transformers/utils/merge.py\", line 527, in <module>\n",
      "    raise ValueError('Merging data files requires either the dataset or a pldb api endpoint')\n",
      "ValueError: Merging data files requires either the dataset or a pldb api endpoint\n",
      "Traceback (most recent call last):\n",
      "  File \"../../transformers/utils/merge.py\", line 527, in <module>\n",
      "    raise ValueError('Merging data files requires either the dataset or a pldb api endpoint')\n",
      "ValueError: Merging data files requires either the dataset or a pldb api endpoint\n",
      "Traceback (most recent call last):\n",
      "  File \"../../transformers/utils/merge.py\", line 527, in <module>\n",
      "    raise ValueError('Merging data files requires either the dataset or a pldb api endpoint')\n",
      "ValueError: Merging data files requires either the dataset or a pldb api endpoint\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'/bin/bash create_feature_matrix.sh ./data/data\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-4641cce25d18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/bin/bash create_feature_matrix.sh ./data/data\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/schrodinger.ve/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2321\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2323\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2324\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/schrodinger.ve/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/leidnerf/schrodinger.ve/lib/python3.6/site-packages/decorator.py:decorator-gen-109>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/schrodinger.ve/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/schrodinger.ve/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'/bin/bash create_feature_matrix.sh ./data/data\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "/bin/bash create_feature_matrix.sh ./data/data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
